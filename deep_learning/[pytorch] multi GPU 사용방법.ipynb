{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f3c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load ibrary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81702f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153da37",
   "metadata": {},
   "source": [
    "## model 정의 한 후에 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi gpu(2개 이상)를 사용하는 경우\n",
    "if use_multi_gpu:\n",
    "    num_gpu = torch.cuda.device_count()\n",
    "    if (device.type=='cuda') and (num_gpu > 1):\n",
    "        print('use multi gpu : %d' % (num_gpu))\n",
    "        model = nn.DataParallel(model, device_ids=list(range(num_gpu)))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848a4eb",
   "metadata": {},
   "source": [
    "#### 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde86e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "model_name = 'efficientnet-b3' \n",
    "num_classes = num_classes \n",
    "use_multi_gpu = True\n",
    "\n",
    "model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n",
    "\n",
    "# multi gpu(2개 이상)를 사용하는 경우\n",
    "if use_multi_gpu:\n",
    "    num_gpu = torch.cuda.device_count()\n",
    "    if (device.type=='cuda') and (num_gpu > 1):\n",
    "        print('use multi gpu : %d' % (num_gpu))\n",
    "        model = nn.DataParallel(model, device_ids=list(range(num_gpu)))\n",
    "        \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9e3bf",
   "metadata": {},
   "source": [
    "### 모델 train하고 모델 저장할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi gpu면 weight key에 'module.'이 붙으므로 떼고 저장\n",
    "if use_multi_gpu:\n",
    "    model_state_dict = model.module.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
